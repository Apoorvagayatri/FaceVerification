# PerspectAI Face Verification System
## Project Report

### 1. Introduction

This report details the implementation of a lightweight face verification system built for PerspectAI. The system is designed to determine whether two facial images belong to the same individual, a crucial component for identity verification applications in online proctoring systems. Our approach leverages Two-Dimensional Principal Component Analysis (2DPCA) for feature extraction and various machine learning algorithms for classification, with the goal of improving upon PerspectAI's existing model (which had 75-85% accuracy).

Two implementations were developed:
1. A primary system (**FaceVerify_2DPCA_MLP.ipynb**, formerly Script_128-2) with a robust MLP classifier
2. An enhanced system (**FaceVerify_Enhanced_Ensemble.ipynb**, formerly Script_final_gen) with ensemble classification methods

### 2. Methodology

#### 2.1 Data Preprocessing

The face verification pipeline begins with preprocessing steps:

- **Face Detection**: Using Viola-Jones face detection (OpenCV's Haar Cascade) to isolate facial regions (ROI)
- **Image Enhancement**: Upscaling low-resolution images using ESRGAN (Enhanced Super-Resolution Generative Adversarial Network)
- **Grayscale Conversion**: Converting detected faces to grayscale to reduce dimension complexity
- **Standardization**: Resizing all detected faces to 64×64 pixels
- **Directory Organization**: Storing processed images in structured directories for efficient access

#### 2.2 Feature Extraction with 2DPCA

For feature extraction, we implemented 2D Principal Component Analysis:

1. **Training Phase**:
   - Computing the image covariance matrix from the training dataset
   - Extracting the top k=30 eigenvectors from this matrix (experimentally determined optimal value)
   - Storing these eigenvectors in pickle files (eig_vecsk_128.pkl, eig_vecsk_128sept10.pkl)

2. **Feature Projection**:
   - Projecting each face image onto the eigenspace using the saved eigenvectors
   - Creating a lower-dimensional representation that captures the essential facial features
   - The coefficient for each Principal Component signifies its similarity or contribution to the given image

#### 2.3 Verification Pair Generation

To train the verification models:

- **Positive Pairs**: Generated by selecting different images of the same person
- **Negative Pairs**: Generated by selecting images from different individuals
- **Balanced Dataset**: Ensuring equal numbers of positive and negative pairs
  - Training set: 21,248 pairs (10,624 positive + 10,624 negative)
  - Validation set: 5,160 pairs (2,580 positive + 2,580 negative)
  - Test set: 8,112 pairs (4,056 positive + 4,056 negative)
- **Feature Combination**: Computing and concatenating feature differences between pairs for classification input

### 3. Classification Approaches

#### 3.1 FaceVerify_2DPCA_MLP.ipynb (Primary Implementation)

The primary system employs multiple classification approaches, with MLP showing the best results:

- **Multi-Layer Perceptron (MLP)**:
  - Architecture: hidden_layer_sizes=(256,128,64)
  - Max iterations: 1000
  - Validation fraction: 0.1
  - Learning rate: 0.001
  - Validation accuracy: 87.03%, Validation precision: 91.23%
  - Test accuracy: 93.23%, Test precision: 91.32%

- **Support Vector Machine (SVM) with RBF kernel**:
  - Hyperparameter Optimization: Used grid search with cross-validation
  - Optimal Parameters: C=10, gamma=1e-08
  - Model Storage: Final model saved as 'svc_rbf_c_10_gamma_1e-08.pkl'

#### 3.2 FaceVerify_Enhanced_Ensemble.ipynb (Enhanced Implementation)

The enhanced system experiments with multiple classification algorithms:

- **Random Forest Classifier**:
  - Implementing ensembles with up to 100,000 decision trees
  - Optimizing tree depth and sample splitting parameters
  - Validation accuracy: 83.08%, Validation precision: 93.56%
  - Test accuracy: 93.09%, Test precision: 93.56%
  - Final model saved as 'rf_classifier10000.pkl'

- **XGBoost Classifier**:
  - objective='binary:logistic', n_estimators=8000
  - Applying gradient boosting for improved performance
  - Fine-tuning learning rate and regularization parameters
  - Validation accuracy: 88.64%, Validation precision: 92.06%
  - Test accuracy: 92.77%, Test precision: 90.61%

- **K-Nearest Neighbors (KNN)**:
  - Testing with k=20 (using only top 20 eigenvectors)
  - Evaluating Euclidean and Minkowski distance metrics
  - Validation accuracy: 81.98%, Validation precision: 77.08%
  - Test accuracy: 82.92%, Test precision: 77.08%

### 4. Performance Evaluation

#### 4.1 Detailed Metrics for MLP Classifier

Performance metrics on the test dataset:
- **Accuracy**: 93.23%
- **Precision**: 
  - Class 0 (different identities): 0.95
  - Class 1 (same identity): 0.92
- **Recall**: 
  - Class 0: 0.92
  - Class 1: 0.96
- **F1 Score**: 
  - Class 0: 0.93
  - Class 1: 0.94
- **AUC-ROC**: 0.93540
- **Equal Error Rate (EER)**: 4.438%

The confusion matrix from a total of 8,112 test pairs shows:
- True Positives: 3,876
- True Negatives: 3,712
- False Positives: 344
- False Negatives: 180

#### 4.2 Computational Efficiency

The MLP classifier demonstrates exceptional efficiency metrics:
- **Inference time**: ~0.038 seconds average (measured over 100 prediction runs)
- **Memory usage**: ~23.77 MB peak (measured using tracemalloc)
- **CPU utilization**: ~19.79% average (sampled over ten 0.1-second intervals)

This computational efficiency makes the system suitable for local deployment on candidate systems with minimal hardware requirements.

### 5. Implementation of ESRGAN for Image Enhancement

We integrated Enhanced Super-Resolution Generative Adversarial Networks (ESRGAN) to improve the quality of low-resolution images typically captured by webcams:

- **Implementation**: Applied to detected face regions (ROI) before standardization
- **Benefit**: 1% increase in verification accuracy compared to non-upscaled images
- **Potential improvements**: The benefits could be further amplified by using larger standardized image sizes (128×128 or 256×256) instead of 64×64, which would preserve more of the enhanced details

### 6. Error Analysis and Challenges

During development, we addressed several challenges:

- **Face Detection Failures**: Most false negatives were due to wrongly detected ROIs by the Viola-Jones algorithm, particularly with:
  - Partial faces in the camera view
  - Complex backgrounds with patterns that confuse the detector
  - Poor lighting conditions

- **Training Data Considerations**:
  - Created balanced verification pairs to prevent classification bias
  - Generated pairs through a systematic process of iterating through all person folders

- **Dimensionality Issues**: 
  - Tested different values of k (10, 15, 20, 25, 30, 35) for PCA components
  - Found k=30 provided optimal accuracy while managing computational load

- **Model Size**: Balanced performance against model size for efficient local deployment

### 7. Local Deployment Capability

A significant advantage of our implementation is its ability to run locally on client systems:

- **Privacy Preservation**: Face data never leaves the user's device
- **Reduced Infrastructure Requirements**: No need for dedicated verification servers
- **Low Latency**: Real-time verification without network dependencies
- **Deployment Package**: Complete system can be deployed using the saved model and eigenvector files

### 8. Promising Areas for Further Development

Future improvements could include:

1. **Resolution Enhancement**: Resize images to 128×128 or 256×256 pixels instead of 64×64 to better leverage ESRGAN upscaling benefits

2. **Dataset Expansion**: Train on more diverse images to improve principle component representation and model accuracy on unknown data

3. **Face Detection Improvement**: Experiment with alternative face detection models like YOLO or MTCNN

4. **Demographic Considerations**: 
   - Ensure principle components represent diverse populations
   - Consider training region-specific models for areas with distinct facial characteristics

5. **Environment Optimization**: Guide candidates to use solid-color backgrounds to minimize face detection errors

6. **Deep Learning Integration**: Explore CNN-based approaches while maintaining the lightweight deployment requirement

### 9. References

1. Yang, J., Zhang, D., Frangi, A. F., & Yang, J. Y. (2004). Two-dimensional PCA: a new approach to appearance-based face representation and recognition. IEEE transactions on pattern analysis and machine intelligence, 26(1), 131-137.

2. Viola, P., & Jones, M. (2001). Rapid object detection using a boosted cascade of simple features. In Proceedings of the 2001 IEEE computer society conference on computer vision and pattern recognition.

3. Wang, X. et al. (2019). ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks. In: Computer Vision – ECCV 2018 Workshops.

4. C. Song, Z. He, Y. Yu and Z. Zhang, "Low Resolution Face Recognition System Based on ESRGAN," 2021 3rd International Conference on Applied Machine Learning (ICAML), Changsha, China, 2021, pp. 76-79.

5. M. Ghizlane, B. Hicham and F. H. Reda, "A New Model of Automatic and Continuous Online Exam Monitoring," 2019 International Conference on Systems of Collaboration Big Data, Internet of Things & Security (SysCoBIoTS), Casablanca, Morocco, 2019, pp. 1-5.

6. Turk, M.A. and Pentland, A.P., 1991. Face recognition using eigenfaces. In Proceedings IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pp. 586-587. 